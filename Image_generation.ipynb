{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39483b5ae584b39acbcd3f637f09fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StableDiffusionPipeline {\n",
       "  \"_class_name\": \"StableDiffusionPipeline\",\n",
       "  \"_diffusers_version\": \"0.23.1\",\n",
       "  \"_name_or_path\": \"CompVis/stable-diffusion-v1-4\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPImageProcessor\"\n",
       "  ],\n",
       "  \"requires_safety_checker\": true,\n",
       "  \"safety_checker\": [\n",
       "    \"stable_diffusion\",\n",
       "    \"StableDiffusionSafetyChecker\"\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"PNDMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "auth_token = #\"write your token here\"\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "device = \"cuda\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_from_prompt(prompt):\n",
    "    try:\n",
    "        # Generate the image using the prompt\n",
    "        image_data = pipe(prompt).images[0]\n",
    "\n",
    "        # Convert the image to a base64 string\n",
    "        buffered = io.BytesIO()\n",
    "        image_data.save(buffered, format=\"PNG\")\n",
    "        image_data_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "        return image_data_base64\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image():\n",
    "    prompt = text_entry.get(\"1.0\", \"end-1c\")\n",
    "    image_data = generate_image_from_prompt(prompt)\n",
    "    if image_data:\n",
    "        # Convert base64 to image and display\n",
    "        image_bytes = base64.b64decode(image_data)\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        image.thumbnail((400, 400))  # Resize to fit the label\n",
    "        photo = ImageTk.PhotoImage(image)\n",
    "        image_label.config(image=photo)\n",
    "        image_label.image = photo  # Keep a reference to prevent garbage collection\n",
    "    else:\n",
    "        print(\"Failed to generate image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8d11eb9784456489462862004229ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Text to Image\")\n",
    "\n",
    "# Create a text entry field\n",
    "text_entry = tk.Text(root, height=10, width=40)\n",
    "text_entry.pack(padx=10, pady=10)\n",
    "\n",
    "# Create a button to generate the image\n",
    "generate_button = tk.Button(root, text=\"Generate Image\", command=generate_image)\n",
    "generate_button.pack(pady=10)\n",
    "\n",
    "# Create a label to display the generated image\n",
    "image_label = tk.Label(root)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
